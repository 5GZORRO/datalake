# 5GZORRO Datalake 

## Overview
This repository contains code and other files to implement the 5GZORRO datalake.

The main datalake API functionality is provided in the directory python-flask-server, much of which was generated by swagger.codegen.

The API itself is specified in datalake_swagger.yaml and datalake_api.html.

This code is work-in-progess.

## Requirements
The datalake server requires that there first be running: [kubernetes](https://github.com/5GZORRO/infrastructure/blob/master/docs/kubernetes.md), [kafka](https://github.com/5GZORRO/infrastructure/blob/master/docs/kafka.md), [argo](https://github.com/5GZORRO/issm/blob/master/docs/argo.md), s3 object store (can be minio).

To set up minio:
```
wget https://dl.min.io/server/minio/release/linux-amd64/minio
chmod +x minio
mkdir /minio/data
export MINIO_VOLUMES="/var/lib/minio"
export MINIO_ACCESS_KEY=user
export MINIO_SECRET_KEY=password
./minio server /minio/data
```
Kubernetes should use Docker container management (rather than containerd) for argo to work properly.

For kubernetes, it is possible to run a simulated minikube cluster.

In Argo, it is necessary to define the argo-events namespace.

The ingest pipeline must be compiled and dockerized with a name of "ingest" before bringing up the datalake python-flask-server.

This is a POC implementation.
Authentication is not yet implemented.

TODO:
Proper permissions have to be set up to use the argo-events (argo-events-resource-admin-role).

## Usage
In the python-flask-server directory, fill in the proper values in env and follow the instructions in the README file.
