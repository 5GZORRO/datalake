# 5GZORRO Datalake 

## Overview
This repository contains code and other files to implement the 5GZORRO datalake.

The main datalake API functionality is provided in the directory python-flask-server, much of which was generated by swagger.codegen.

The API itself is specified in datalake_swagger.yaml.

This code is work-in-progess.

## Requirements
The datalake server requires that there first be running: [kubernetes](https://github.com/5GZORRO/infrastructure/blob/master/docs/kubernetes.md), [kafka](https://github.com/5GZORRO/infrastructure/blob/master/docs/kafka.md), [argo](https://github.com/5GZORRO/issm/blob/master/docs/argo.md), s3 object store (can be minio).

To set up minio:
```
wget https://dl.min.io/server/minio/release/linux-amd64/minio
chmod +x minio
mkdir /minio/data
export MINIO_VOLUMES="/var/lib/minio"
export MINIO_ACCESS_KEY=user
export MINIO_SECRET_KEY=password
./minio server /minio/data
```
Kubernetes should use Docker container management (rather than containerd) for argo to work properly.

For kubernetes, it is possible to run a simulated minikube cluster.

To set up Argo and standard argo-events:
```
kubectl create namespace argo
kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo/v2.12.0-rc3/manifests/install.yaml
kubectl create rolebinding default-admin --clusterrole=admin --serviceaccount=default:default
kubectl create namespace argo-events
kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/v1.1.0/manifests/install.yaml
kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/v1.1.0/examples/eventbus/native.yaml
```
In Argo, it is necessary to define the `dl-argo-events` namespace.
```
kubectl create namespace dl-argo-events
cd config
kubectl apply -f ./install.yaml
kubectl apply -n dl-argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/v1.1.0/examples/eventbus/native.yaml
```

To see the Argo GUI, run `argo server` at the command line, and then connect via a web browser to `http://localhost:2746`.

In Kubernetes, it is necessary to define the `datalake` namespace.
```
kubectl create namespace datalake
```

The ingest pipeline must be compiled and dockerized with a name of `ingest` before bringing up the datalake python-flask-server.

This is a POC implementation.
Authentication is not yet implemented.

TODO:
Proper permissions have to be set up to use the argo-events (argo-events-resource-admin-role).

## Usage
In the python-flask-server directory, fill in the proper values in env and follow the instructions in the README file.
